{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trabajo Práctico N° 2\n",
    "## Objetivo:\n",
    "\n",
    "Para cada dispositivo presentado por Jampp, determinar el tiempo que transcurrirá hasta que el mismo aparezca nuevamente en una subasta, y el tiempo hasta que el usuario del mismo decida instalar una nueva aplicación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import auc, accuracy_score\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict, GridSearchCV, KFold, RandomizedSearchCV, train_test_split\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Primero veo los dispositivos del target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = pd.read_csv('data/target_competencia_ids.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tomo los ref_hash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target['ref_hash'] = target['ref_hash'].transform(lambda x: str(x)[:-3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target['ref_hash'] = target['ref_hash'].astype(np.int64)\n",
    "target.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target.drop_duplicates(subset = 'ref_hash', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculo cuanto tiempo tarda un dispositivo en aparecer en una subasta contando desde el inicio de la ventana que quiero predecir\n",
    "\n",
    "La idea es determinar el tiempo que transcurrió entre cada aparición de un dispositivo en una subasta, para luego tomar el tiempo mínimo de aparición de un dispositivo en una subasta y de acuerdo a eso predecir utilizando los features de la ventana anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auct_predict = pd.read_csv('data/auctions_ventana7.csv', dtype = { \"ref_type_id\": np.int8, \"source_id\": np.int8})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "auct_predict['date'] = pd.to_datetime(auct_predict['date'])\n",
    "auct_predict['date_inicial'] = dt.datetime(2019,4, 24)\n",
    "auct_predict['timeToAuction'] = (auct_predict['date'] - auct_predict['date_inicial'])/np.timedelta64(1,'s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auct_predict['timeToAuction'] = auct_predict['timeToAuction'].transform(lambda x: (72 * 60 * 60) if (x < 0) else x)\n",
    "auct_predict.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tomo el tiempo mínimo, en SEGUNDOS, que tardó cada dispositivo en aparecer en una subasta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auction_time = auct_predict.groupby('device_id').agg({'timeToAuction': 'min'}).reset_index()\n",
    "auction_time.columns = ['ref_hash', 'predict_value']\n",
    "auction_time.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auction_time = target[['ref_hash']].merge(auction_time, on = 'ref_hash', how = 'left')\n",
    "auction_time['predict_value'] = auction_time['predict_value'].fillna((72 * 60 * 60)) # Los que no aparecieron "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auction_time.merge(target[['ref_hash']]).nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analizo los datos de la ventana anterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auct = pd.read_csv('data/auctions_ventana7.csv', dtype = { \"ref_type_id\": np.int8, \"source_id\": np.int8})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auct.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auct['date'] = pd.to_datetime(auct['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auct.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Veo cuantas veces aparece cada dispositivo en una subasta\n",
    "\n",
    "Inicio sencillamente contando la cantidad de subastas en las que participó cada dispositivo, y lo agrego como un nuevo feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auction_count = auct.groupby('device_id').agg({'date': 'count'}).reset_index()\n",
    "auction_count.columns = ['ref_hash', 'auctions_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auction_count.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creo un único set de datos con los primeros features creados usando los ids de los dispositivos de la ventana 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = auction_time.merge(auction_count, on = 'ref_hash', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pruebo con Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "\n",
    "y = data['predict_value']\n",
    "X = data.drop(['ref_hash', 'predict_value'], axis=1)\n",
    "\n",
    "RFR = RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=2,\n",
    "           max_features='auto', max_leaf_nodes=None,\n",
    "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "           min_samples_leaf=1, min_samples_split=2,\n",
    "           min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=None,\n",
    "           oob_score=False, random_state=0, verbose=0, warm_start=False)\n",
    "RFR.fit(X, y)  \n",
    "RFR.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = cross_val_predict(RFR, X, y, cv=10)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(RFR, X, y, cv=5, scoring='neg_mean_squared_error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculo el RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convierto los valores a MSE scores\n",
    "mse_scores = -scores\n",
    "# paso de MSE a RMSE\n",
    "rmse_scores = np.sqrt(mse_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rmse_scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pruebo con xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "y = data['predict_value']\n",
    "X = data.drop(['ref_hash', 'predict_value'], axis=1)\n",
    "\n",
    "XGB = xgb.XGBRegressor()\n",
    "XGB.fit(X, y)\n",
    "\n",
    "scores = cross_val_score(XGB , X, y, scoring = \"neg_mean_squared_error\", cv=5)\n",
    "\n",
    "mse_scores = -scores\n",
    "# paso de MSE a RMSE\n",
    "rmse_scores = np.sqrt(mse_scores)\n",
    "rmse_scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Veo la cantidad de veces que aparece cada dispositivo segun el source_id\n",
    "\n",
    "Ahora me interesa ver la cantidad de veces que un dispositivo participó en una subasta desde cada tipo de fuente desde donde se produce la subasta. De esta manera los source_id más populares tomaran un valor mayor, luego tomo la desviación estándar de la cantidad para cada device_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auct['apariciones'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auction_by_sourceID = auct.groupby(['device_id', 'source_id']).agg({'apariciones':'sum'}).unstack(1).fillna(0).reset_index()\n",
    "auction_by_sourceID.columns = auction_by_sourceID.columns.droplevel(0)\n",
    "auction_by_sourceID.columns = ['ref_hash', 'source_id0', 'source_id1', 'source_id2', 'source_id3', 'source_id4', 'source_id5', 'source_id6', 'source_id7', 'source_id8', 'source_id9']\n",
    "auction_by_sourceID.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auction_by_sourceID['auctions_by_srcID'] = auction_by_sourceID.iloc[:,1:].std(axis = 1)\n",
    "auction_by_sourceID.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agrego el nuevo feature a los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = auction_time.merge(auction_by_sourceID, on = 'ref_hash', how = 'left')#data.merge(auction_by_sourceID[['ref_hash', 'auctions_by_srcID']], on = 'ref_hash')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vuelvo a probar el modelo con el nuevo feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data1['predict_value']\n",
    "X = data1.drop(['ref_hash', 'predict_value'], axis=1)\n",
    "\n",
    "RFR = RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=2,\n",
    "           max_features='auto', max_leaf_nodes=None,\n",
    "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "           min_samples_leaf=1, min_samples_split=2,\n",
    "           min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=None,\n",
    "           oob_score=False, random_state=0, verbose=0, warm_start=False)\n",
    "RFR.fit(X, y)  \n",
    "\n",
    "RFR.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_predict(RFR, X, y, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(RFR, X, y, cv=10, scoring='neg_mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# RMSE\n",
    "mse_scores = -scores\n",
    "rmse_scores = np.sqrt(mse_scores)\n",
    "rmse_scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pruebo xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data1['predict_value']\n",
    "X = data1.drop(['ref_hash', 'predict_value'], axis=1)\n",
    "\n",
    "XGB = xgb.XGBRegressor()\n",
    "XGB.fit(X, y)\n",
    "\n",
    "scores = cross_val_score(XGB , X, y, scoring = \"neg_mean_squared_error\", cv=5)\n",
    "\n",
    "mse_scores = -scores\n",
    "# paso de MSE a RMSE\n",
    "rmse_scores = np.sqrt(mse_scores)\n",
    "rmse_scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El nuevo feature logró bajar el score promedio de RMSE, así que lo mantenemos en el dataset de features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Veo la cantidad de veces que aparece cada dispositivo en una subasta según el ref_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auct['ref_type_id'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfApRef = auct.groupby(['device_id', 'ref_type_id']).agg({'apariciones':'sum'}).unstack(1).fillna(0).reset_index()\n",
    "dfApRef.columns = dfApRef.columns.droplevel(0)\n",
    "dfApRef['median_count_ref_type'] = dfApRef.median(axis = 1)\n",
    "dfApRef.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Me interesa ver si cada usuario sólo tiene apariciones para el mismo ref_type, lo chequeo para ver si me servirá o no el feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfApRef.columns = ['ref_hash', 'auctions_ref_type1', 'auctions_ref_type7', 'median_count_ref_type']\n",
    "dfApRef.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfApRef['aparece_en_distinto_ref_type'] = ((dfApRef['auctions_ref_type1'] > 0) & (dfApRef['auctions_ref_type7'] > 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfApRef.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfApRef['aparece_en_distinto_ref_type'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como hay valores para ref_types distintos puedo probar agregar este feature y ver que sucede"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data2 = data1.merge(dfApRef[['ref_hash', 'median_count_ref_type']], on = 'ref_hash', how = 'left')\n",
    "data2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data2['predict_value']\n",
    "X = data2.drop(['ref_hash', 'predict_value'], axis=1)\n",
    "\n",
    "RFR = RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=2,\n",
    "           max_features='auto', max_leaf_nodes=None,\n",
    "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "           min_samples_leaf=1, min_samples_split=2,\n",
    "           min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=None,\n",
    "           oob_score=False, random_state=0, verbose=0, warm_start=False)\n",
    "RFR.fit(X, y)  \n",
    "\n",
    "RFR.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_predict(RFR, X, y, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(RFR, X, y, cv=5, scoring='neg_mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RMSE\n",
    "mse_scores = -scores\n",
    "rmse_scores = np.sqrt(mse_scores)\n",
    "rmse_scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data2['predict_value']\n",
    "X = data2.drop(['ref_hash', 'predict_value'], axis=1)\n",
    "\n",
    "XGB = xgb.XGBRegressor()\n",
    "XGB.fit(X, y)\n",
    "\n",
    "scores = cross_val_score(XGB , X, y, scoring = \"neg_mean_squared_error\", cv=5)\n",
    "\n",
    "mse_scores = -scores\n",
    "# paso de MSE a RMSE\n",
    "rmse_scores = np.sqrt(mse_scores)\n",
    "rmse_scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El valor del score bajó así que mantenemos estos features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cantidad de apariciones de un dispositivo en las subastas por día\n",
    "\n",
    "Calculo la cantidad de apariciones para cada dispositivo en las subastas por día, luego tomo la mediana para las apariciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auct['fecha'] = auct['date'].dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfApDay = auct.groupby(['device_id', 'fecha']).agg({'apariciones':'sum'}).unstack(1).fillna(0).reset_index()\n",
    "dfApDay.columns = dfApDay.columns.droplevel(0)\n",
    "dfApDay.columns = ['ref_hash', '2019-04-23', '2019-04-24', '2019-04-25']\n",
    "dfApDay['auctions_by_day'] = dfApDay.median(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfApDay.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agrego el nuevo feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data3 = data1.merge(dfApDay[['ref_hash', 'auctions_by_day']], on = 'ref_hash', how = 'left')\n",
    "data3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data3.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora puebo el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data3['predict_value']\n",
    "X = data3.drop(['ref_hash', 'predict_value'], axis=1)\n",
    "\n",
    "RFR = RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=2,\n",
    "           max_features='auto', max_leaf_nodes=None,\n",
    "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "           min_samples_leaf=1, min_samples_split=2,\n",
    "           min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=None,\n",
    "           oob_score=False, random_state=0, verbose=0, warm_start=False)\n",
    "RFR.fit(X, y)  \n",
    "\n",
    "RFR.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_predict(RFR, X, y, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(RFR, X, y, cv=5, scoring='neg_mean_squared_error')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RMSE\n",
    "mse_scores = -scores\n",
    "rmse_scores = np.sqrt(mse_scores)\n",
    "rmse_scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pruebo con Gradient Boosting Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "GBR = GradientBoostingRegressor(random_state=23, n_estimators=50, min_samples_split=50)\n",
    "scores = cross_val_score(GBR , X, y, scoring = \"neg_mean_squared_error\", cv=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RMSE\n",
    "mse_scores = -scores\n",
    "rmse_scores = np.sqrt(mse_scores)\n",
    "rmse_scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ahora pruebo con XGBoost "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "XGB = xgb.XGBRegressor()\n",
    "\n",
    "scores = cross_val_score(XGB , X, y, scoring = \"neg_mean_squared_error\", cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RMSE\n",
    "mse_scores = -scores\n",
    "rmse_scores = np.sqrt(mse_scores)\n",
    "rmse_scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El score con xgboost bajó, así que voy a mantener este feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agrego como feature el tiempo minimo de aparición de un dispositivo durante la ventana anterior a la ventana en la que voy a predecir.\n",
    "\n",
    "La idea de este feature es estudiar el comportamiento de los dispositivos, sus tiempos de aparición y calcular el mínimo tiempo entre ellos para tener un estimativo del tiempo a predecir.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apariciones_auctions = auct[['date', 'device_id']]\n",
    "apariciones_auctions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "apariciones_auctions['date'] = pd.to_datetime(apariciones_auctions['date'])\n",
    "apariciones_auctions['date_inicial'] = dt.datetime(2019,4, 24)\n",
    "apariciones_auctions['timeToAuction'] = (apariciones_auctions['date'] - apariciones_auctions['date_inicial'])/np.timedelta64(1,'s')\n",
    "apariciones_auctions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apariciones_auctions = apariciones_auctions.groupby('device_id').agg({'timeToAuction': 'min'}).reset_index()\n",
    "apariciones_auctions.columns = ['ref_hash', 'timeToAuction_min']\n",
    "apariciones_auctions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agrego el nuevo feature "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data4 = data3.merge(apariciones_auctions, on = 'ref_hash', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data4.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pruebo con XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data4['predict_value']\n",
    "X = data4.drop(['ref_hash', 'predict_value'], axis=1)\n",
    "\n",
    "XGB = xgb.XGBRegressor()\n",
    "XGB.fit(X, y)\n",
    "\n",
    "scores = cross_val_score(XGB , X, y, scoring = \"neg_mean_squared_error\", cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RMSE\n",
    "mse_scores = -scores\n",
    "rmse_scores = np.sqrt(mse_scores)\n",
    "rmse_scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este feature mejoró muchísimo el score, lo mantengo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agrego Features sobre los eventos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evts = pd.read_csv(\"data/events_ventana7.csv\", dtype = {\"event_id\": np.int16, \"application_id\": np.int16, 'device_countrycode': 'category', 'device_os_version': 'category', 'device_brand': 'category', 'device_model': 'category', 'device_city': 'category', 'session_user_agent': 'category', 'trans_id': 'category', 'user_agent': 'category', 'carrier' : 'category', 'kind': 'category', 'device_os': 'category', 'connection_type': 'category', 'ip_address': 'category', 'device_language': 'category'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "evts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aplicaciones populares\n",
    "\n",
    "Agrego Features tomando en cuenta cuales la popularidad de las applicaciones. La idea es generar un feature que asigne un número a cada dispositivo de acuerdo al id de la applicación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apps_populares = evts[['application_id', 'ref_hash']].groupby('application_id').count().reset_index()\n",
    "apps_populares.columns = ['application_id', 'popularidad_app']\n",
    "apps_populares.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apps_populares = evts[['ref_hash', 'application_id']].merge(apps_populares, on = 'application_id')\n",
    "apps_populares.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apps_counts = evts[['date', 'ref_hash', 'application_id']].groupby(['ref_hash', 'application_id']).count().reset_index()\n",
    "apps_counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Le asigno a cada dispositivo la popularidad de la applicación en la cual generó más eventos\n",
    "apps_pops = apps_counts.groupby(['ref_hash']).agg({'date': 'max'}).reset_index()\n",
    "apps_pops.columns = ['ref_hash', 'popularidad_events']\n",
    "apps_pops.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agrego el nuevo feature a los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data5 = data4.merge(apps_pops, on = 'ref_hash', how = 'left')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data5.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pruebo el feature con XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data5['predict_value']\n",
    "X = data5.drop(['ref_hash', 'predict_value'], axis=1)\n",
    "\n",
    "XGB = xgb.XGBRegressor()\n",
    "XGB.fit(X, y)\n",
    "\n",
    "scores = cross_val_score(XGB , X, y, scoring = \"neg_mean_squared_error\", cv=5)\n",
    "\n",
    "# RMSE\n",
    "mse_scores = -scores\n",
    "rmse_scores = np.sqrt(mse_scores)\n",
    "rmse_scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "con este feature el score bajó un poco así que lo mantengo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agrego un feature tomando en cuenta la cantidad de eventos en los que participó cada dispositivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_events = evts.groupby('ref_hash').agg({'date': 'count'}).reset_index()\n",
    "count_events.columns = ['ref_hash', 'count_events']\n",
    "count_events.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agrego el nuevo feature y veo qué sucede con el score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data6 = data5.merge(count_events, on = 'ref_hash', how = 'left')\n",
    "#data['count_events'] = data['count_events'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data6.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vuelvo a probar el modelo con XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "y = data6['predict_value']\n",
    "X = data6.drop(['ref_hash', 'predict_value'], axis=1)\n",
    "\n",
    "XGB = xgb.XGBRegressor()\n",
    "XGB.fit(X, y)\n",
    "\n",
    "scores = cross_val_score(XGB , X, y, scoring = \"neg_mean_squared_error\", cv=5)\n",
    "\n",
    "# RMSE\n",
    "mse_scores = -scores\n",
    "rmse_scores = np.sqrt(mse_scores)\n",
    "rmse_scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "se puede ver que este feature empeoró el score, así que lo descartamos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agrego el tiempo que tarda cada dispositivo en generar el primer evento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events_time = evts[['date', 'ref_hash']]\n",
    "events_time['date'] = pd.to_datetime(evts['date'])\n",
    "events_time['date_inicial'] = dt.datetime(2019,4, 24)\n",
    "events_time['timeToEvent'] = (events_time['date'] - events_time['date_inicial'])/np.timedelta64(1,'s')\n",
    "events_time.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events_time = events_time.groupby('ref_hash').agg({'timeToEvent': 'min'}).reset_index()\n",
    "events_time.columns = ['ref_hash', 'timeToEvent_min']\n",
    "events_time.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agrego el nuevo feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data7 = data5.merge(events_time, on = 'ref_hash', how = 'left')\n",
    "data7.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data7.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pruebo el modelo con el nuevo feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data7['predict_value']\n",
    "X = data7.drop(['ref_hash', 'predict_value'], axis=1)\n",
    "\n",
    "XGB = xgb.XGBRegressor(learning_rate =0.075, n_estimators=95, max_depth=4, min_child_weight=6, \n",
    "                         gamma=0.3, subsample=0.8, colsample_bytree=0.8,\n",
    "                         scale_pos_weight=0.8, seed = 15)\n",
    "XGB.fit(X, y)\n",
    "\n",
    "scores = cross_val_score(XGB , X, y, scoring = \"neg_mean_squared_error\", cv=5)\n",
    "\n",
    "# RMSE\n",
    "mse_scores = -scores\n",
    "rmse_scores = np.sqrt(mse_scores)\n",
    "rmse_scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con este feature el score volvió a subir, así que lo descartamos "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Busco los mejores hiperparámetros para xgboost utilizando Ramdomize search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XGB = xgb.XGBRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "parameters_for_testing = {'max_depth': [3, 4],\n",
    "                          'learning_rate': [0.1,0.2],\n",
    "                          'n_estimators': [50, 100], \n",
    "                          'objective': ['reg:linear'],\n",
    "                          'n_jobs': [1,2], \n",
    "                          'gamma': [0,0.2], \n",
    "                          'min_child_weight': [0.5,1],\n",
    "                          'subsample': [0.9, 1], \n",
    "                          'colsample_bytree': [0.9,1],\n",
    "                          'reg_alpha': [0,0.1], \n",
    "                          'reg_lambda': [0.9, 1]}\n",
    "\n",
    "                    \n",
    "xgb_model = xgb.XGBRegressor()\n",
    "\n",
    "gsearch1 = GridSearchCV(estimator = xgb_model, param_grid = parameters_for_testing, n_jobs=6,iid=False, verbose=10,scoring='neg_mean_squared_error')\n",
    "gsearch1.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('best params')\n",
    "print (gsearch1.best_params_)\n",
    "print('best score')\n",
    "print (gsearch1.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = -gsearch1.best_score_\n",
    "rmse = np.sqrt(score)\n",
    "rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pruebo los features anteriores para predecir los tiempos de conversiones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inst = pd.read_csv('data/installs_ventana7.csv', dtype = {'application_id': np.int16, 'ref_type': 'category', 'click_hash': 'category', 'device_country_code': 'category', 'device_brand': 'category', 'device_model': 'category', 'kind': 'category', 'device_language': 'category'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installs\n",
    "\n",
    "Tomo los tiempos de la primera conversión de cada dispositivo dentro de la ventana 2 para entrenar el algoritmo luego"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inst['created'] = pd.to_datetime(inst['created'])\n",
    "inst.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculo el tiempo que tarda en convertir cada dispositivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inst['created_inicial'] = dt.datetime(2019, 4, 24)\n",
    "inst['created_inicial'] = pd.to_datetime(inst['created_inicial'])\n",
    "inst['timeToInstall'] = (inst['created'] - inst['created_inicial'])/np.timedelta64(1,'s')\n",
    "inst['timeToInstall'] = inst['timeToInstall'].transform(lambda x: x if (x >=  0) else (72 * 60 * 60))\n",
    "inst.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tomo el tiempo mínimo, en SEGUNDOS, que tardó un dispositivo en realizar una instalación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "install_time = inst.groupby('ref_hash').agg({'timeToInstall': 'min'}).reset_index()\n",
    "install_time.columns = ['ref_hash', 'predict_time_install']\n",
    "install_time.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "install_time = target[['ref_hash']].merge(install_time, on = 'ref_hash', how = 'left')\n",
    "install_time['predict_time_install'] = install_time['predict_time_install'].fillna(72 * 60 * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "install_time.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ahora leo los datos de la ventana  para crear features sobre estos ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "installs = pd.read_csv('data/installs_ventana7.csv', dtype = {'application_id': np.int16, 'ref_type': 'category', 'click_hash': 'category', 'device_country_code': 'category', 'device_brand': 'category', 'device_model': 'category', 'kind': 'category', 'device_language': 'category'})\n",
    "installs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agrego un feature sobre la popularidad de las applicaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apps_populares_installs = installs.groupby('application_id').agg({'created': 'count'}).reset_index()\n",
    "apps_populares_installs.columns = ['application_id', 'popularidad_app']\n",
    "apps_populares_installs = installs[['ref_hash', 'application_id']].merge(apps_populares_installs, on = 'application_id')\n",
    "apps_populares_installs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apps_counts = installs.groupby(['ref_hash', 'application_id']).agg({'created': 'count'}).reset_index()\n",
    "# Le asigno a cada dispositivo la popularidad de la applicación en la cual generó más eventos\n",
    "apps_pops = apps_counts.groupby(['ref_hash']).agg({'created': 'max'}).reset_index()\n",
    "apps_pops.columns = ['ref_hash', 'popularidad_apps']\n",
    "apps_pops.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creo el set de datos par a entrenar los algoritmos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_installs = install_time.merge(apps_pops, on = 'ref_hash', how = 'left') \n",
    "data_installs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_installs.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pruebo XGBoost para predecir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data_installs['predict_time_install']\n",
    "X = data_installs.drop(['ref_hash', 'predict_time_install'], axis=1)\n",
    "\n",
    "XGB = xgb.XGBRegressor( max_depth=3, learning_rate=0.1, n_estimators=100,\n",
    "                       verbosity=1, silent=None, objective='reg:linear', n_jobs=1, gamma=0,\n",
    "                       min_child_weight=1,  max_delta_step=0, reg_alpha=0, reg_lambda=1, \n",
    "                       scale_pos_weight=1, base_score=0.5, random_state=0, importance_type='gain')\n",
    "XGB.fit(X, y)\n",
    "\n",
    "scores = cross_val_score(XGB , X, y, scoring = \"neg_mean_squared_error\", cv=5)\n",
    "\n",
    "# RMSE\n",
    "mse_scores = -scores\n",
    "rmse_scores = np.sqrt(mse_scores)\n",
    "rmse_scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agrego como feature el tiempo real que tarda un dispositivo en realizar la primera conversión, dentro de la ventana 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "installs['created'] = pd.to_datetime(inst['created'])\n",
    "installs['created_inicial'] = dt.datetime(2019, 4, 24)\n",
    "installs['created_inicial'] = pd.to_datetime(installs['created_inicial'])\n",
    "installs['timeToInstall'] = (installs['created'] - installs['created_inicial'])/np.timedelta64(1,'s')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ahora tomo el tiempo mínimo\n",
    "time_to_install = installs.groupby('ref_hash').agg({'timeToInstall': 'min'}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_to_install.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agrego el  nuevo feature y vuelvo a probar el algoritmo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_installs1 = data_installs.merge(time_to_install, on = 'ref_hash', how = 'left')\n",
    "data_installs1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_installs1.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data_installs1['predict_time_install']\n",
    "X = data_installs1.drop(['ref_hash', 'predict_time_install'], axis=1)\n",
    "\n",
    "XGB = xgb.XGBRegressor( max_depth=3, learning_rate=0.1, n_estimators=100,\n",
    "                       verbosity=1, silent=None, objective='reg:linear', n_jobs=1, gamma=0,\n",
    "                       min_child_weight=1,  max_delta_step=0, reg_alpha=0, reg_lambda=1, \n",
    "                       scale_pos_weight=1, base_score=0.5, random_state=0, importance_type='gain')\n",
    "\n",
    "scores = cross_val_score(XGB , X, y, scoring = \"neg_mean_squared_error\", cv=5)\n",
    "\n",
    "# RMSE\n",
    "mse_scores = -scores\n",
    "rmse_scores = np.sqrt(mse_scores)\n",
    "rmse_scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se mejoró el score, por lo que mantengo el feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ahora agrego los features sobre los eventos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data1 = data_installs1.merge(apps_pops, on = 'ref_hash', how = 'left')\n",
    "new_data1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data1.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pruebo el nuevo feature con xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = new_data1['predict_time_install']\n",
    "X = new_data1.drop(['ref_hash', 'predict_time_install'], axis=1)\n",
    "\n",
    "XGB = xgb.XGBRegressor()\n",
    "XGB.fit(X, y)\n",
    "\n",
    "scores = cross_val_score(XGB , X, y, scoring = \"neg_mean_squared_error\", cv=5)\n",
    "\n",
    "# RMSE\n",
    "mse_scores = -scores\n",
    "rmse_scores = np.sqrt(mse_scores)\n",
    "rmse_scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El score se mantuvo igual, por lo que puedo sospechar que las apps populares en events son las mismas que en installs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agrego un feature sobre los eventos registrados para cada dispositivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data2 = data_installs1.merge(count_events, on = 'ref_hash', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data2.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new_data['count_events'] = new_data['count_events'].fillna(0.0)\n",
    "y = new_data2['predict_time_install']\n",
    "X = new_data2.drop(['ref_hash', 'predict_time_install'], axis=1)\n",
    "\n",
    "XGB = xgb.XGBRegressor( max_depth=3, learning_rate=0.1, n_estimators=100,\n",
    "                       verbosity=1, silent=None, objective='reg:linear', n_jobs=1, gamma=0,\n",
    "                       min_child_weight=1,  max_delta_step=0, reg_alpha=0, reg_lambda=1, \n",
    "                       scale_pos_weight=1, base_score=0.5, random_state=0, importance_type='gain')\n",
    "\n",
    "scores = cross_val_score(XGB , X, y, scoring = \"neg_mean_squared_error\", cv=5)\n",
    "\n",
    "# RMSE\n",
    "mse_scores = -scores\n",
    "rmse_scores = np.sqrt(mse_scores)\n",
    "rmse_scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se logró mejorar el score con este feature, así que lo mantengo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agrego los features sobre auctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#agrego la mediana de subastas registradas por cada dispositivo según el ref_type_id\n",
    "new_data3 = new_data2.merge(dfApRef[['ref_hash', 'median_count_ref_type']], on = 'ref_hash', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data3.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new_data['median_count_ref_type'] = new_data['median_count_ref_type'].fillna(0.0)\n",
    "y = new_data3['predict_time_install']\n",
    "X = new_data3.drop(['ref_hash', 'predict_time_install'], axis=1)\n",
    "\n",
    "XGB = xgb.XGBRegressor()\n",
    "XGB.fit(X, y)\n",
    "\n",
    "scores = cross_val_score(XGB , X, y, scoring = \"neg_mean_squared_error\", cv=5)\n",
    "\n",
    "# RMSE\n",
    "mse_scores = -scores\n",
    "rmse_scores = np.sqrt(mse_scores)\n",
    "rmse_scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El feature anterior empeoró las performance por lo que no se lo tomará en cuenta para las predicciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#agrego la cantidad de subastas registradas para cada dispositivo\n",
    "new_data4 = new_data2.merge(auction_count, on = 'ref_hash', how = 'left')\n",
    "new_data4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data4.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##new_data['auction_count'] = new_data['auctions_count'].fillna(0.0)\n",
    "y = new_data4['predict_time_install']\n",
    "X = new_data4.drop(['ref_hash', 'predict_time_install'], axis=1)\n",
    "\n",
    "XGB = xgb.XGBRegressor()\n",
    "XGB.fit(X, y)\n",
    "\n",
    "scores = cross_val_score(XGB , X, y, scoring = \"neg_mean_squared_error\", cv=5)\n",
    "\n",
    "# RMSE\n",
    "mse_scores = -scores\n",
    "rmse_scores = np.sqrt(mse_scores)\n",
    "rmse_scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El feature anterior tampoco logró mejorar el score, aunque no lo empeoró, por ahora no lo tomo en cuenta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Agrego el tiempo mínimo de aparición de cada dispositivo en una subasta\n",
    "new_data5 = new_data2.merge(apariciones_auctions, on = 'ref_hash', how  = 'left')\n",
    "new_data5.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data5.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new_data[ 'auctions_by_srcID'] = new_data[ 'auctions_by_srcID'].fillna(0.0)\n",
    "y = new_data5['predict_time_install']\n",
    "X = new_data5.drop(['ref_hash', 'predict_time_install'], axis=1)\n",
    "\n",
    "XGB = xgb.XGBRegressor()\n",
    "XGB.fit(X, y)\n",
    "\n",
    "scores = cross_val_score(XGB , X, y, scoring = \"neg_mean_squared_error\", cv=5)\n",
    "\n",
    "# RMSE\n",
    "mse_scores = -scores\n",
    "rmse_scores = np.sqrt(mse_scores)\n",
    "rmse_scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se puede apreciar que con este nuevo feature se mejoró bastante el score, así que lo mantendremos entre los features para las predicciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agrego otro feature, tomando en cuenta el promedio de subastas, por día, en las que participa cada dispositivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data6 = new_data5.merge(dfApDay[['ref_hash', 'auctions_by_day']], on = 'ref_hash', how  = 'left')\n",
    "new_data6.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data6.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora pruebo el modelo con los nuevos features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#new_data['timeToAuction_min'] = new_data['timeToAuction_min'].fillna(72 * 60 * 60)\n",
    "y = new_data6['predict_time_install']\n",
    "X = new_data6.drop(['ref_hash', 'predict_time_install'], axis=1)\n",
    "\n",
    "XGB = xgb.XGBRegressor()\n",
    "XGB.fit(X, y)\n",
    "\n",
    "scores = cross_val_score(XGB , X, y, scoring = \"neg_mean_squared_error\", cv=5)\n",
    "\n",
    "# RMSE\n",
    "mse_scores = -scores\n",
    "rmse_scores = np.sqrt(mse_scores)\n",
    "rmse_scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este feature hizo que el score empeore un poco, así que no lo mantendré en cuenta\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agrego un nuevo feature tomando en cuenta el user_agent desde donde se origina la instalación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "installs_by_user_agent = installs[['user_agent', 'ref_hash']].groupby('user_agent').count().reset_index()\n",
    "installs_by_user_agent.columns = ['user_agent', 'installs_por_user_agent']\n",
    "installs_by_user_agent = installs_by_user_agent.merge(installs[['ref_hash', 'user_agent']], on = 'user_agent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "installs_by_user_agent.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data7 = new_data5.merge(installs_by_user_agent[['installs_por_user_agent', 'ref_hash']], on = 'ref_hash', how = 'left')\n",
    "new_data7.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data7.merge(target[['ref_hash']]).nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pruebo el nuevo feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new_data[ 'auctions_by_srcID'] = new_data[ 'auctions_by_srcID'].fillna(0.0)\n",
    "y = new_data7['predict_time_install']\n",
    "X = new_data7.drop(['ref_hash', 'predict_time_install'], axis=1)\n",
    "\n",
    "XGB = xgb.XGBRegressor()\n",
    "XGB.fit(X, y)\n",
    "\n",
    "scores = cross_val_score(XGB , X, y, scoring = \"neg_mean_squared_error\", cv=5)\n",
    "\n",
    "# RMSE\n",
    "mse_scores = -scores\n",
    "rmse_scores = np.sqrt(mse_scores)\n",
    "rmse_scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con el nuevo feature el score mejoró bastante así que lo mantengo, hasta ahora el mejor es new_data7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agrego un nuevo feature tomando en cuenta la session_user_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_user_agent = installs[['ref_hash', 'session_user_agent']].groupby('session_user_agent').count().reset_index()\n",
    "session_user_agent.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_feature = installs[['ref_hash', 'session_user_agent']].merge(session_user_agent, on = 'session_user_agent', how = 'left')\n",
    "session_feature = session_feature.drop(columns = 'session_user_agent')\n",
    "session_feature.columns = ['ref_hash', 'session_user_agent']\n",
    "session_feature.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agrego el nuevo feature al set de features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data8 = new_data7.merge(session_feature, on = 'ref_hash', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data8.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pruebo el nuevo feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = new_data8['predict_time_install']\n",
    "X = new_data8.drop(['ref_hash', 'predict_time_install'], axis=1)\n",
    "\n",
    "XGB = xgb.XGBRegressor()\n",
    "XGB.fit(X, y)\n",
    "\n",
    "scores = cross_val_score(XGB , X, y, scoring = \"neg_mean_squared_error\", cv=5)\n",
    "\n",
    "# RMSE\n",
    "mse_scores = -scores\n",
    "rmse_scores = np.sqrt(mse_scores)\n",
    "rmse_scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este feature empeoró el score, así que lo descarto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Guardo los features de cada ventana"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features sobre st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#data7.to_csv(path_or_buf = 'features_anteriores_St.csv', index = False)\n",
    "#Leo los datos de la ventana anterior\n",
    "features = pd.read_csv('features_anteriores_St.csv')\n",
    "features['predict_value'] = features['predict_value'].fillna(72 * 60 * 60)\n",
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "features = features.merge(target[['ref_hash']])\n",
    "y_train = features['predict_value']\n",
    "X_train = features.drop(['ref_hash', 'predict_value'], axis=1)\n",
    "\n",
    "XGB = xgb.XGBRegressor( max_depth=3, learning_rate=0.1, n_estimators=100,\n",
    "                       verbosity=1, silent=None, objective='reg:linear', n_jobs=1, gamma=0,\n",
    "                       min_child_weight=1,  max_delta_step=0, reg_alpha=0, reg_lambda=1, \n",
    "                       scale_pos_weight=1, base_score=0.5, random_state=0, importance_type='gain')\n",
    "\n",
    "scores = cross_val_score(XGB , X_train, y_train, scoring = \"neg_mean_squared_error\", cv=5)\n",
    "\n",
    "# RMSE\n",
    "mse_scores = -scores\n",
    "rmse_scores = np.sqrt(mse_scores)\n",
    "rmse_scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_final = data7.merge(target[['ref_hash']], on = 'ref_hash')\n",
    "data_final = data_final.drop(columns = ['ref_hash', 'predict_value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XGB = xgb.XGBRegressor( max_depth=3, learning_rate=0.1, n_estimators=100,\n",
    "                       verbosity=1, silent=None, objective='reg:linear', n_jobs=1, gamma=0,\n",
    "                       min_child_weight=1,  max_delta_step=0, reg_alpha=0, reg_lambda=1, \n",
    "                       scale_pos_weight=1, base_score=0.5, random_state=0, importance_type='gain')\n",
    "XGB.fit(X_train, y_train)\n",
    "result = XGB.predict(data_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_st = target.drop(columns = 'obj')\n",
    "target_st.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = []\n",
    "for l in result:\n",
    "    submit.append(l)\n",
    "target_st['obj'] = submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_st['ref_hash'] = target_st['ref_hash'].transform(lambda x: str(x) + '_st')\n",
    "target_st.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target.to_csv(path_or_buf = \"submit_st.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creo las predicciones sc con todos los ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new_data7.to_csv(path_or_buf = 'features_anteriores_Sc.csv', index = False)\n",
    "# Cargo los features de la ventana anterior\n",
    "features_train = pd.read_csv('features_anteriores_Sc.csv')\n",
    "features_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = features_train['predict_time_install']\n",
    "X_train = features_train.drop(['ref_hash', 'predict_time_install'], axis=1)\n",
    "\n",
    "XGB = xgb.XGBRegressor( max_depth=3, learning_rate=0.1, n_estimators=100,\n",
    "                       verbosity=1, silent=None, objective='reg:linear', n_jobs=1, gamma=0,\n",
    "                       min_child_weight=1,  max_delta_step=0, reg_alpha=0, reg_lambda=1, \n",
    "                       scale_pos_weight=1, base_score=0.5, random_state=0, importance_type='gain')\n",
    "\n",
    "scores = cross_val_score(XGB , X_train, y_train, scoring = \"neg_mean_squared_error\", cv=5)\n",
    "\n",
    "# RMSE\n",
    "mse_scores = -scores\n",
    "rmse_scores = np.sqrt(mse_scores)\n",
    "rmse_scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_final = new_data7.drop(columns = ['ref_hash','predict_time_install'])\n",
    "feature_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XGB = xgb.XGBRegressor()\n",
    "XGB.fit(X_train, y_train)\n",
    "result2 = XGB.predict(feature_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "target_sc = target.drop(columns = 'obj')\n",
    "target.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = []\n",
    "for l in result:\n",
    "    submit.append(l)\n",
    "target_sc['obj'] = submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_sc['ref_hash'] = target_sc['ref_hash'].transform(lambda x: str(x)[ + '_sc'])\n",
    "target_sc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target.to_csv(path_or_buf = \"submit_sc.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Armo el submit final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st = pd.read_csv('submit_st.csv')\n",
    "st.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = pd.read_csv('submit_sc.csv')\n",
    "sc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_final = target_st.merge(target_sc, on = 'ref_hash', how = 'outer')\n",
    "submit_final = submit_final.sort_values(by = 'ref_hash')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_final['obj_x'] = submit_final['obj_x'].fillna(0)\n",
    "submit_final['obj_y'] = submit_final['obj_y'].fillna(0)\n",
    "submit_final['obj'] = submit_final['obj_x'] + submit_final['obj_y']\n",
    "submit_final = submit_final[['ref_hash', 'obj']]\n",
    "submit_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_final.to_csv(path_or_buf = 'submit_final2.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_final.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
